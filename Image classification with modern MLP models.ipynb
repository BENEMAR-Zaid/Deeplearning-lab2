{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87260afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25058721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 182s 1us/step\n",
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "'''In this step we download and load the data set and split it into two parts ( Train and test sets ) \n",
    "then printing the shape of each set\n",
    "'''\n",
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa96871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 64 X 64 = 4096\n",
      "Patch size: 8 X 8 = 64 \n",
      "Patches per image: 64\n",
      "Elements per patch (3 channels): 192\n"
     ]
    }
   ],
   "source": [
    "'''Now we set hyperparameters like the size of image and patches that will extracted from the image and number of blocks.\n",
    "'''\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.2\n",
    "image_size = 64  # We'll resize input images to this size.\n",
    "patch_size = 8  # Size of the patches to be extracted from the input images.\n",
    "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
    "embedding_dim = 256  # Number of hidden units.\n",
    "num_blocks = 4  # Number of blocks.\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
    "print(f\"Patches per image: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6eac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''After setting hyperparameters we will build a classifier model. \n",
    "'''\n",
    "def build_classifier(blocks, positional_encoding=False):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size, num_patches)(augmented)\n",
    "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
    "    x = layers.Dense(units=embedding_dim)(patches)\n",
    "    if positional_encoding:\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=embedding_dim\n",
    "        )(positions)\n",
    "        x = x + position_embedding\n",
    "    # Process x using the module blocks.\n",
    "    x = blocks(x)\n",
    "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor.\n",
    "    representation = layers.GlobalAveragePooling1D()(x)\n",
    "    # Apply dropout.\n",
    "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
    "    # Compute logits outputs.\n",
    "    logits = layers.Dense(num_classes)(representation)\n",
    "    # Create the Keras model.\n",
    "    return keras.Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b2da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''we will fit our model befor the test, we choosed categorical_crossentropy as loss function and adam instead of GD \n",
    "as optimizer'''\n",
    "def run_experiment(model):\n",
    "    # Create Adam optimizer with weight decay.\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
    "    )\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
    "        ],\n",
    "    )\n",
    "    # Create a learning rate scheduler callback.\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=5\n",
    "    )\n",
    "    # Create an early stopping callback.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    )\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "    )\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    # Return history to plot learning curves.\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d91c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "because our data is not big, and for training our model we need huge number of images to give us good results, there is a technique\n",
    "called data augmentation so we will try to apply that to our dataset.\n",
    "What data augmentation do is random horizontal flipping or small random rotations.\n",
    "'''\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b305aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we will implement a layer that extract patches of each image'''\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, num_patches):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bf216",
   "metadata": {},
   "source": [
    "# The MLP-Mixer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc51931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' the MLP-Mixer is based on multi-layer perceptrons that generally contains 2 types : \n",
    "1- The one who mixes the per-location features of an image independently\n",
    "2- The one who mixes spatial information across patches'''\n",
    "\n",
    "class MLPMixerLayer(layers.Layer):\n",
    "    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n",
    "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.mlp1 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=num_patches),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "        self.mlp2 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=embedding_dim),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply layer normalization.\n",
    "        x = self.normalize(inputs)\n",
    "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
    "        x_channels = tf.linalg.matrix_transpose(x)\n",
    "        # Apply mlp1 on each channel independently.\n",
    "        mlp1_outputs = self.mlp1(x_channels)\n",
    "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
    "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
    "        # Add skip connection.\n",
    "        x = mlp1_outputs + inputs\n",
    "        # Apply layer normalization.\n",
    "        x_patches = self.normalize(x)\n",
    "        # Apply mlp2 on each patch independtenly.\n",
    "        mlp2_outputs = self.mlp2(x_patches)\n",
    "        # Add skip connection.\n",
    "        x = x + mlp2_outputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''we will fit our model before the test'''\n",
    "mlpmixer_blocks = keras.Sequential(\n",
    "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
    ")\n",
    "learning_rate = 0.005\n",
    "mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n",
    "'''Here we will run the model on new data that he has never seen '''\n",
    "history = run_experiment(mlpmixer_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553d8ee",
   "metadata": {},
   "source": [
    "# The FNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d53fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''What FNet do is replaces the self-attention layer in the Transformer block, \n",
    "which make him a similar block to the Trasnformer block.\n",
    "The transfomartion is done with a parameter-free 2D Fourier that we will try to build it in this step'''\n",
    "\n",
    "class FNetLayer(layers.Layer):\n",
    "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
    "        super(FNetLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embedding_dim),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "                layers.Dense(units=embedding_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply fourier transformations.\n",
    "        x = tf.cast(\n",
    "            tf.signal.fft2d(tf.cast(inputs, dtype=tf.dtypes.complex64)),\n",
    "            dtype=tf.dtypes.float32,\n",
    "        )\n",
    "        # Add skip connection.\n",
    "        x = x + inputs\n",
    "        # Apply layer normalization.\n",
    "        x = self.normalize1(x)\n",
    "        # Apply Feedfowrad network.\n",
    "        x_ffn = self.ffn(x)\n",
    "        # Add skip connection.\n",
    "        x = x + x_ffn\n",
    "        # Apply layer normalization.\n",
    "        return self.normalize2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d950b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''we will fit our model befor the test'''\n",
    "fnet_blocks = keras.Sequential(\n",
    "    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
    ")\n",
    "learning_rate = 0.001\n",
    "fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n",
    "'''Here we will run the model on new data that he has never seen '''\n",
    "history = run_experiment(fnet_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26937277",
   "metadata": {},
   "source": [
    "# The gMLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85a90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The gMLP based on multi-layer perceptrons that features a Spatial Gating Unit (SGU). The cross-patch interactions across \n",
    "the spatial dimenstion is done by : \n",
    "1-Transforming the input spatially by applying linear projection across patches (along channels).\n",
    "2-Applying element-wise multiplication of the input and its spatial transformation. '''\n",
    "\n",
    "class gMLPLayer(layers.Layer):\n",
    "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
    "        super(gMLPLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.channel_projection1 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embedding_dim * 2),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.channel_projection2 = layers.Dense(units=embedding_dim)\n",
    "\n",
    "        self.spatial_projection = layers.Dense(\n",
    "            units=num_patches, bias_initializer=\"Ones\"\n",
    "        )\n",
    "\n",
    "        self.normalize1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.normalize2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def spatial_gating_unit(self, x):\n",
    "        # Split x along the channel dimensions.\n",
    "        # Tensors u and v will in th shape of [batch_size, num_patchs, embedding_dim].\n",
    "        u, v = tf.split(x, num_or_size_splits=2, axis=2)\n",
    "        # Apply layer normalization.\n",
    "        v = self.normalize2(v)\n",
    "        # Apply spatial projection.\n",
    "        v_channels = tf.linalg.matrix_transpose(v)\n",
    "        v_projected = self.spatial_projection(v_channels)\n",
    "        v_projected = tf.linalg.matrix_transpose(v_projected)\n",
    "        # Apply element-wise multiplication.\n",
    "        return u * v_projected\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply layer normalization.\n",
    "        x = self.normalize1(inputs)\n",
    "        # Apply the first channel projection. x_projected shape: [batch_size, num_patches, embedding_dim * 2].\n",
    "        x_projected = self.channel_projection1(x)\n",
    "        # Apply the spatial gating unit. x_spatial shape: [batch_size, num_patches, embedding_dim].\n",
    "        x_spatial = self.spatial_gating_unit(x_projected)\n",
    "        # Apply the second channel projection. x_projected shape: [batch_size, num_patches, embedding_dim].\n",
    "        x_projected = self.channel_projection2(x_spatial)\n",
    "        # Add skip connection.\n",
    "        return x + x_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmlp_blocks = keras.Sequential(\n",
    "    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n",
    ")\n",
    "learning_rate = 0.003\n",
    "gmlp_classifier = build_classifier(gmlp_blocks)\n",
    "history = run_experiment(gmlp_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this exemple we have first of all prepared the data that we will work with and setting the hyperparameter for the builded model. Because our data is not big, and for training our model we need huge number of images to give us good results, there is a technique called data augmentation so we will try to apply that to our dataset. What data augmentation do is random horizontal flipping or small random rotations.\n",
    "Second we implements three modern attention-free, multi-layer perceptron (MLP) based models for image classification :\n",
    "1-The MLP-Mixer model\n",
    "2-The FNet model\n",
    "3-The gMLP model\n",
    "The purpose is not to compare between them and theire performances but to practice the implementation of their main building blocks and how they works.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
